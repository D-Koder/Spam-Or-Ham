{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming Vs Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Stemming?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming refers to chopping off the end of a word to get the root word. It uses crude heuristic way of finding the root word from a given word. It is faster than Lemmatizing but not always finds the correct root word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean\n",
      "mean\n",
      "mean\n"
     ]
    }
   ],
   "source": [
    "print(ps.stem('mean'))\n",
    "print(ps.stem('meaning'))\n",
    "print(ps.stem('meanness'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grow\n",
      "grow\n",
      "grew\n"
     ]
    }
   ],
   "source": [
    "print(ps.stem('grow'))\n",
    "print(ps.stem('growing'))\n",
    "print(ps.stem('grew'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go\n",
      "gone\n",
      "went\n"
     ]
    }
   ],
   "source": [
    "print(ps.stem('go'))\n",
    "print(ps.stem('gone'))\n",
    "print(ps.stem('went'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goos\n",
      "gees\n"
     ]
    }
   ],
   "source": [
    "print(ps.stem('goose'))\n",
    "print(ps.stem('geese'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see stemmer reduces the word to its root word but is not always right. It will output different root words for the forms of the same word which do not resemble each other such as 'go','went' and 'gone'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Lemmatization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization tends to do the same thing as that of Stemming i.e. getting the root of a word but it uses a more vocabulary based approach where it analyses words to get the base dictionary form of a word. Due to its more complex process, it takes longer than the Stemmer but is more accurate than it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import WordNetLemmatizer\n",
    "\n",
    "wn = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goose\n",
      "goose\n"
     ]
    }
   ],
   "source": [
    "print(wn.lemmatize('goose'))\n",
    "print(wn.lemmatize('geese'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean\n",
      "meaning\n",
      "meanness\n"
     ]
    }
   ],
   "source": [
    "print(wn.lemmatize('mean'))\n",
    "print(wn.lemmatize('meaning'))\n",
    "print(wn.lemmatize('meanness'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go\n",
      "went\n",
      "gone\n"
     ]
    }
   ],
   "source": [
    "print(wn.lemmatize('go'))\n",
    "print(wn.lemmatize('went'))\n",
    "print(wn.lemmatize('gone'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write\n",
      "writing\n",
      "written\n"
     ]
    }
   ],
   "source": [
    "print(wn.lemmatize('write'))\n",
    "print(wn.lemmatize('writing'))\n",
    "print(wn.lemmatize('written'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see here, Lemmatizer is better than stemmer in some ways as it returns dictionary based root forms of a word rather than just chopping off the words. But it too is not perfect and it cannot return base form of those words which are not present in its dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
